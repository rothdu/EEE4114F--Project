{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94fb0e20",
   "metadata": {},
   "source": [
    "# EEE4113F 2024 Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7ea6d",
   "metadata": {},
   "source": [
    "## Necesary imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814f9fe1-589d-41bb-a801-06081ca4319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "from torchvision import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch import flatten\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daee304",
   "metadata": {},
   "source": [
    "## Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9b7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"Snare\", \"Trumpet\", \"Violin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf945f-4365-4621-a6e6-99cdafaf9c7b",
   "metadata": {},
   "source": [
    "## Create dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140b7766-38e1-4ec7-88b1-f58eb59963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InstrumentsDataset(Dataset):\n",
    "    \"\"\"Instruments dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.instrument_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instrument_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.instrument_frame.iloc[idx, 0])\n",
    "        # image = io.read_image(img_name, mode=ImageReadMode.GRAY)\n",
    "        # image = io.read_image(img_name)\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        \n",
    "        instrument = self.instrument_frame.iloc[idx, 1]\n",
    "        instrument_id = classes.index(instrument)\n",
    "\n",
    "        return image, instrument_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd6d2f",
   "metadata": {},
   "source": [
    "##  CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8030ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, numChannels,numClasses):\n",
    "  \n",
    "        super(SimpleModel, self).__init__()\n",
    "        #First layer (convolutional)\n",
    "        self.conv1 = nn.Conv2d(numChannels, 6, 3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(4, 4)\n",
    "\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.LazyLinear(120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.LazyLinear(numClasses)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x\n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self, numChannels,numClasses):\n",
    "  \n",
    "        super(ComplexModel, self).__init__()\n",
    "        #First layer (convolutional)\n",
    "        self.conv1 = nn.Conv2d(numChannels, 6, 3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second layer (also convolutional)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.LazyLinear(120)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.LazyLinear(50)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.LazyLinear(numClasses)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        # conv layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # conv layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        # linear layer 1\n",
    "        x = flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        # linear layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        # linear layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = self.logsoftmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493ed7e",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cea728-4851-48a3-aa7a-f131b68eb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.Grayscale(),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5), (0.5)),\n",
    "#      transforms.Resize((64, 64))])\n",
    "\n",
    "def generateDataloaders(input_csv):\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    train_val_dataset = InstrumentsDataset(csv_file = input_csv, root_dir = \".\", transform=trans)\n",
    "\n",
    "    train_size = int(0.8 * len(train_val_dataset))\n",
    "    val_size = len(train_val_dataset) - train_size\n",
    "\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# trans = transforms.Compose([\n",
    "#     transforms.Grayscale(),\n",
    "#     transforms.ToTensor()\n",
    "#     # transforms.Resize((64, 64))\n",
    "#     ])\n",
    "\n",
    "# # trans = transforms.Compose([\n",
    "# #     transforms.ToTensor(),\n",
    "# #     transforms.Resize((64, 64))\n",
    "# #     ])\n",
    "\n",
    "# train_val_dataset = InstrumentsDataset(csv_file = \"../Training-data/hann.csv\", root_dir = \".\", transform=trans)\n",
    "# # train_val_dataset = InstrumentsDataset(csv_file=\"../Training-data/mfcc.csv\", root_dir = \".\", transform=trans)\n",
    "# test_dataset = InstrumentsDataset(csv_file = \"../Test-data/hann.csv\", root_dir = \".\", transform = trans)\n",
    "\n",
    "# train_size = int(0.8 * len(train_val_dataset))\n",
    "# val_size = len(train_val_dataset) - train_size\n",
    "\n",
    "\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c8a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that dataset is generating as expected...\n",
    "\n",
    "\n",
    "# image, instrument_id = train_dataset[0]\n",
    "\n",
    "# print(image)\n",
    "# print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67089a59",
   "metadata": {},
   "source": [
    "## Go and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a623ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/venv/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(1, len(classes)) # 1 channel for grayscale at this stage, or 3 for the MFCCs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c04ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    # initialise evaluation parameters\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad(): # evaluating so don't produce gradients\n",
    "        for data in loader:\n",
    "            inputs, labels = data # get data from dataloader\n",
    "            outputs = model(inputs) # predict outputs\n",
    "            loss = criterion(outputs, labels) # calculate current loss\n",
    "            _, predicted = torch.max(outputs.data, 1) # calculate predicted data\n",
    "            total += labels.size(0) # total number of labels in the current batch\n",
    "            correct += (predicted == labels).sum().item() # number of labels that are correct\n",
    "            \n",
    "            running_loss += loss.item() # loss? not 100% sure\n",
    "        \n",
    "    # Return mean loss, accuracy\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def runModel(model, train_loader, val_loader):\n",
    "\n",
    "    loss_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [], \n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(8):  # loop over the dataset multiple times\n",
    "        print(\"Starting Epoch: {}\".format(epoch+1))\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        # num_iterations = 0\n",
    "        plt_axis = []\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            model.train()\n",
    "            \n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history['train_loss'].append(loss.item())\n",
    "            val_loss, val_acc = evaluate(model, val_loader)\n",
    "            loss_history['val_loss'].append(val_loss)\n",
    "            loss_history['val_acc'].append(val_acc)\n",
    "            iteration+=1\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    return loss_history\n",
    "\n",
    "\n",
    "# Notes for tomorrow:\n",
    "# Check what type of data is being input / output\n",
    "# Look at a tutorial on custom pytorch image recognition?\n",
    "# https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc\n",
    "# https://glassboxmedicine.com/2021/02/06/designing-custom-2d-and-3d-cnns-in-pytorch-tutorial-with-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb06d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "# print(\"Loss:\", mean_loss, \"Accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "871ef49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss_history['train_loss'], label='train_loss')\n",
    "# plt.plot(loss_history['val_loss'], label='val_loss')\n",
    "# plt.ylim((0, 5))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be49de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateResults(window_type, complexity):\n",
    "    if (complexity == \"Complex\"):\n",
    "        model = ComplexModel(1, len(classes))\n",
    "    else:\n",
    "        model = SimpleModel(1, len(classes))\n",
    "    \n",
    "    train_loader, val_loader = generateDataloaders(\"../Training-data/\" + window_type + \".csv\")\n",
    "    loss_history = runModel(model, train_loader, val_loader)\n",
    "\n",
    "    out_list = list(zip(loss_history['train_loss'], loss_history['val_loss'], loss_history['val_acc']))\n",
    "\n",
    "    df = pd.DataFrame(out_list)\n",
    "    print(df)\n",
    "    df.to_csv(\"../Spectrogram Results/\" + complexity + \"/\" + window_type + \".csv\", index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a53e4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/venv/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 1\n",
      "Finished Training\n",
      "          0         1         2\n",
      "0  1.102325  1.107369  0.307692\n",
      "1  1.092161  1.107369  0.307692\n",
      "2  1.103564  1.107369  0.307692\n",
      "3  1.113402  1.107369  0.307692\n",
      "4  1.107054  1.107369  0.307692\n",
      "5  1.103843  1.107369  0.307692\n",
      "6  1.086272  1.107369  0.307692\n",
      "7  1.102978  1.107369  0.307692\n",
      "8  1.091842  1.107369  0.307692\n",
      "9  1.099450  1.107369  0.307692\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in ('hann', 'blackman', 'rectangular'):\n",
    "    for j in ['Simple', 'Complex']:\n",
    "        generateResults(i, j)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
