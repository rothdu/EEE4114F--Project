{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94fb0e20",
   "metadata": {},
   "source": [
    "# EEE4113F 2024 Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7ea6d",
   "metadata": {},
   "source": [
    "## Necesary imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814f9fe1-589d-41bb-a801-06081ca4319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "from torchvision import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch import flatten\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daee304",
   "metadata": {},
   "source": [
    "## Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9b7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"Snare\", \"Trumpet\", \"Violin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf945f-4365-4621-a6e6-99cdafaf9c7b",
   "metadata": {},
   "source": [
    "## Create dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140b7766-38e1-4ec7-88b1-f58eb59963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InstrumentsDataset(Dataset):\n",
    "    \"\"\"Instruments dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.instrument_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instrument_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.instrument_frame.iloc[idx, 0])\n",
    "        # image = io.read_image(img_name, mode=ImageReadMode.GRAY)\n",
    "        # image = io.read_image(img_name)\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        \n",
    "        instrument = self.instrument_frame.iloc[idx, 1]\n",
    "        instrument_id = classes.index(instrument)\n",
    "\n",
    "        return image, instrument_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd6d2f",
   "metadata": {},
   "source": [
    "##  CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8030ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, numChannels,numClasses):\n",
    "  \n",
    "        super(SimpleModel, self).__init__()\n",
    "        #First layer (convolutional)\n",
    "        self.conv1 = nn.Conv2d(numChannels, 6, kernel_size=(1, 4))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(4, 4)\n",
    "\n",
    "\n",
    "        # Linear layers\n",
    "        self.fc1 = nn.LazyLinear(120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.LazyLinear(numClasses)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        # x = self.maxpool1(x)\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x\n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self, numChannels,numClasses):\n",
    "  \n",
    "        super(ComplexModel, self).__init__()\n",
    "        #First layer (convolutional)\n",
    "        self.conv1 = nn.Conv2d(numChannels, 6, 3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second layer (also convolutional)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.LazyLinear(120)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.LazyLinear(50)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.LazyLinear(numClasses)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        # conv layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # conv layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        # linear layer 1\n",
    "        x = flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        # linear layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        # linear layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = self.logsoftmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493ed7e",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cea728-4851-48a3-aa7a-f131b68eb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.Grayscale(),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5), (0.5)),\n",
    "#      transforms.Resize((64, 64))])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    # transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Resize((64, 64))\n",
    "    ])\n",
    "\n",
    "# trans = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Resize((64, 64))\n",
    "#     ])\n",
    "\n",
    "# train_val_dataset = InstrumentsDataset(csv_file = \"../Training-data/hann.csv\", root_dir = \".\", transform=trans)\n",
    "train_val_dataset = InstrumentsDataset(csv_file=\"../Training-data/mfcc.csv\", root_dir = \".\", transform=trans)\n",
    "test_dataset = InstrumentsDataset(csv_file = \"../Test-data/hann.csv\", root_dir = \".\", transform = trans)\n",
    "\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c8a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9569, 0.9569, 0.9569,  ..., 0.9569, 0.9569, 0.9569],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9569, 0.9569, 0.9569],\n",
      "         [0.9569, 0.9569, 0.9569,  ..., 0.9569, 0.9569, 0.9569],\n",
      "         ...,\n",
      "         [0.9373, 0.9373, 0.9373,  ..., 0.8353, 0.8353, 0.8353],\n",
      "         [0.9373, 0.9373, 0.9373,  ..., 0.8353, 0.8353, 0.8353],\n",
      "         [0.9373, 0.9373, 0.9373,  ..., 0.8353, 0.8353, 0.8353]],\n",
      "\n",
      "        [[0.6039, 0.6039, 0.6039,  ..., 0.6039, 0.6039, 0.6039],\n",
      "         [0.6039, 0.6039, 0.6039,  ..., 0.6039, 0.6039, 0.6039],\n",
      "         [0.6039, 0.6039, 0.6039,  ..., 0.6039, 0.6039, 0.6039],\n",
      "         ...,\n",
      "         [0.8078, 0.8078, 0.8078,  ..., 0.8588, 0.8588, 0.8588],\n",
      "         [0.8078, 0.8078, 0.8078,  ..., 0.8588, 0.8588, 0.8588],\n",
      "         [0.8078, 0.8078, 0.8078,  ..., 0.8588, 0.8588, 0.8588]],\n",
      "\n",
      "        [[0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
      "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
      "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
      "         ...,\n",
      "         [0.7412, 0.7412, 0.7412,  ..., 0.8980, 0.8980, 0.8980],\n",
      "         [0.7412, 0.7412, 0.7412,  ..., 0.8980, 0.8980, 0.8980],\n",
      "         [0.7412, 0.7412, 0.7412,  ..., 0.8980, 0.8980, 0.8980]]])\n",
      "torch.Size([3, 400, 1000])\n"
     ]
    }
   ],
   "source": [
    "image, instrument_id = train_dataset[0]\n",
    "\n",
    "print(image)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67089a59",
   "metadata": {},
   "source": [
    "## Go and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c04ef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/venv/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(3, len(classes)) # 1 channel for grayscale at this stage, or 3 for the MFCCs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    # initialise evaluation parameters\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad(): # evaluating so don't produce gradients\n",
    "        for data in loader:\n",
    "            inputs, labels = data # get data from dataloader\n",
    "            outputs = model(inputs) # predict outputs\n",
    "            loss = criterion(outputs, labels) # calculate current loss\n",
    "            _, predicted = torch.max(outputs.data, 1) # calculate predicted data\n",
    "            total += labels.size(0) # total number of labels in the current batch\n",
    "            correct += (predicted == labels).sum().item() # number of labels that are correct\n",
    "            \n",
    "            running_loss += loss.item() # loss? not 100% sure\n",
    "        \n",
    "    # Return mean loss, accuracy\n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "loss_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': []\n",
    "}\n",
    "\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    print(\"Starting Epoch: {}\".format(epoch+1))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        model.train()\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 5 mini-batches\n",
    "            mean_loss = running_loss / 100\n",
    "            loss_history['train_loss'].append(mean_loss)\n",
    "            print('# mini-batch {}\\ntrain loss: {}'.format(\n",
    "                  i + 1, mean_loss))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            # evaluate on validation dataset\n",
    "            mean_loss, val_acc = evaluate(model, val_loader)\n",
    "            loss_history['val_loss'].append(mean_loss)\n",
    "                  \n",
    "            print(\"validation loss: {} validation accuracy: {}\\n\".format(mean_loss, val_acc))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "# Notes for tomorrow:\n",
    "# Check what type of data is being input / output\n",
    "# Look at a tutorial on custom pytorch image recognition?\n",
    "# https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc\n",
    "# https://glassboxmedicine.com/2021/02/06/designing-custom-2d-and-3d-cnns-in-pytorch-tutorial-with-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ef49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
