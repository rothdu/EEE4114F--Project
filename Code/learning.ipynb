{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814f9fe1-589d-41bb-a801-06081ca4319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import scipy.signal as spsig\n",
    "import scipy.signal.windows as spwin\n",
    "\n",
    "import random\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b187fe4-4099-48a0-b782-5621d948f74b",
   "metadata": {},
   "source": [
    "## Generate Spectrograms\n",
    "Basically convert a .wav or .mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe72a760-ad5a-4240-a3a4-f7d82a090595",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# filter out audio files\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.flac\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     27\u001b[0m     \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# load sound files\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# librosa is convenient because it resamples and downscales to mono automatically\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     y_orig, fs \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msound_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msound_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# set output time and corresponding number of samples\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     output_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# seconds\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    205\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[1;32m    211\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/soundfile.py:1205\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1204\u001b[0m             file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mencode(_sys\u001b[38;5;241m.\u001b[39mgetfilesystemencoding())\n\u001b[0;32m-> 1205\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m \u001b[43mopenfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1207\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_fd(file, mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, closefd)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create spectrograms\n",
    "\n",
    "# array of sound types available\n",
    "sound_types = [\"Snare\", \"Trumpet\", \"Violin\"]\n",
    "\n",
    "# iterate over each of the sound types\n",
    "for sound_type in sound_types:\n",
    "\n",
    "    # establish output directories\n",
    "    # TODO: Add checks that directorties exist\n",
    "    sound_dir = os.fsencode(\"../Sounds/\" + sound_type)\n",
    "    spec_dir = os.fsencode(\"../Spectrograms/\" + sound_type)\n",
    "    \n",
    "    # remove all existing spectrograms\n",
    "    for spec_file in os.listdir(spec_dir):\n",
    "        filename = os.fsdecode(spec_file)\n",
    "        if filename.endswith(\".png\"):\n",
    "            os.remove(os.path.join(spec_dir, spec_file))\n",
    "\n",
    "\n",
    "    # iterate over each file (in each directory)\n",
    "    for sound_file in os.listdir(sound_dir):\n",
    "        filename = os.fsdecode(sound_file)\n",
    "\n",
    "        # filter out audio files\n",
    "        if filename.endswith(\".wav\") or filename.endswith(\".mp3\" or filename.endswith(\".flac\")):\n",
    "            \n",
    "            # load sound files\n",
    "            # librosa is convenient because it resamples and downscales to mono automatically\n",
    "            y_orig, fs = librosa.load(os.path.join(sound_dir, sound_file), mono=True, sr=48000)\n",
    "\n",
    "            # set output time and corresponding number of samples\n",
    "            output_time = 1 # seconds\n",
    "            output_len = output_time * fs\n",
    "\n",
    "            # number of samples of loaded file\n",
    "            input_len = np.shape(y_orig)[0]\n",
    "\n",
    "            # skip if loaded file is too short analyse\n",
    "            if input_len < output_len:\n",
    "                print(filename, \"is too short, skipping conversion\")\n",
    "                continue\n",
    "            \n",
    "            # find a section with a high rms value\n",
    "            jump = output_len//2 # spacing between sections\n",
    "            rms_best = 0\n",
    "            rms_best_start = 0\n",
    "\n",
    "            # loop over sections of the sample to find the big with the best rms value\n",
    "            for start in range(0, input_len - output_len, jump):\n",
    "                end = start + output_len\n",
    "                rms = np.sqrt(np.mean(np.square(y_orig[start:end])))\n",
    "                if rms > rms_best:\n",
    "                    rms_best = rms\n",
    "                    rms_best_start = start\n",
    "\n",
    "            # window with best RMS value\n",
    "            y = y_orig[rms_best_start:rms_best_start + output_len]\n",
    "\n",
    "            # Compute the Short-Time Fourier Transform (STFT)\n",
    "            # D = librosa.stft(y)\n",
    "\n",
    "            # STFT calc for spectrogramss\n",
    "\n",
    "            imgsize = 128\n",
    "\n",
    "            T_x, N = 1 / fs, output_len  # 20 Hz sampling rate for 50 s signal\n",
    "\n",
    "            t_x = np.arange(N) * T_x  # time indexes for signal\n",
    "\n",
    "\n",
    "            win = np.ones(1000)#spwin.hamming(1000) \n",
    "            hop = output_len//imgsize\n",
    "\n",
    "            # SFT = spsig.ShortTimeFFT(win, hop=hop, fs=fs, mfft=16000, scale_to='psd')\n",
    "            SFT = spsig.ShortTimeFFT(win, hop=hop, fs=fs, scale_to='psd')\n",
    "\n",
    "            Sx2 = SFT.spectrogram(y)  # calculate absolute square of STFT\n",
    "\n",
    "            Sx_dB = 10 * np.log10(np.fmax(Sx2, 1e-4))  # limit range to -40 dB\n",
    "\n",
    "            fig1, ax1 = plt.subplots(figsize=(6., 4.))  # enlarge plot a bit\n",
    "\n",
    "            # t_lo, t_hi = SFT.extent(N)[:2]  # time range of plot\n",
    "\n",
    "            # ax1.set_title(\"Spectrogram\")\n",
    "            # plt.pcolormesh(f, t, Sx_dB, shading=\"auto\")\n",
    "\n",
    "            # ax1.set(xlim=(t_lo, t_hi))\n",
    "            im1 = ax1.imshow(Sx_dB, origin='lower', aspect='auto', extent=SFT.extent(N), cmap='viridis')\n",
    "\n",
    "            # Shade areas where window slices stick out to the side:\n",
    "            # for t0_, t1_ in [(t_lo, SFT.lower_border_end[0] * SFT.T),\n",
    "\n",
    "            #                 (SFT.upper_border_begin(N)[0] * SFT.T, t_hi)]:\n",
    "\n",
    "            #     ax1.axvspan(t0_, t1_, color='w', linewidth=0, alpha=.3)\n",
    "\n",
    "            # for t_ in [0, N * SFT.T]:  # mark signal borders with vertical line\n",
    "\n",
    "            #     ax1.axvline(t_, color='c', linestyle='--', alpha=0.5)\n",
    "\n",
    "            # fig1.tight_layout()\n",
    "\n",
    "            # Convert the amplitude spectrogram to decibels\n",
    "            # D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "            # # Plot the spectrogram without axis labels or scales\n",
    "            # librosa.display.specshow(Sx_dB, sr=fs, x_axis=None, y_axis=None)\n",
    "\n",
    "            # # Save the spectrogram as a PNG file\n",
    "            output_file = os.path.join(spec_dir, os.fsencode(os.path.splitext(filename)[0] + \".png\"))\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(output_file, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b246693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Create arrays of ground truth data\n",
    "\n",
    "sound_types = [\"Snare\", \"Trumpet\", \"Violin\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for sound_type in sound_types:\n",
    "\n",
    "    # establish output directories\n",
    "    # TODO: Add checks that directorties exist\n",
    "    spec_dir = os.fsencode(\"../Spectrograms/\" + sound_type)\n",
    "    \n",
    "    # remove all existing spectrograms\n",
    "    for spec_file in os.listdir(spec_dir):\n",
    "        \n",
    "        filename = os.fsdecode(spec_file)\n",
    "        \n",
    "        if filename.endswith(\".png\"):\n",
    "\n",
    "            data.append([os.fsdecode(os.path.join(spec_dir, spec_file)), sound_type])\n",
    "\n",
    "key = lambda row: row[0] \n",
    "\n",
    "data.sort(key=lambda item: item[0])\n",
    "\n",
    "with open('groundtruthdata.csv', 'w+') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf945f-4365-4621-a6e6-99cdafaf9c7b",
   "metadata": {},
   "source": [
    "## Create dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "140b7766-38e1-4ec7-88b1-f58eb59963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from skimage import io, transform\n",
    "from torchvision import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InstrumentsDataset(Dataset):\n",
    "    \"\"\"Instruments dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.instrument_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instrument_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.instrument_frame.iloc[idx, 0])\n",
    "        image = io.read_image(img_name)\n",
    "        instrument = self.instrument_frame.iloc[idx, 1]\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return image, instrument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52cea728-4851-48a3-aa7a-f131b68eb44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (369, 496, 4) Snare\n",
      "1 (369, 496, 4) Snare\n",
      "2 (369, 496, 4) Snare\n",
      "3 (369, 496, 4) Snare\n",
      "4 (369, 496, 4) Snare\n",
      "5 (369, 496, 4) Snare\n",
      "6 (369, 496, 4) Snare\n",
      "7 (369, 496, 4) Snare\n",
      "8 (369, 496, 4) Snare\n",
      "9 (369, 496, 4) Snare\n",
      "10 (369, 496, 4) Snare\n",
      "11 (369, 496, 4) Snare\n",
      "12 (369, 496, 4) Snare\n",
      "13 (369, 496, 4) Snare\n",
      "14 (369, 496, 4) Snare\n",
      "15 (369, 496, 4) Snare\n",
      "16 (369, 496, 4) Snare\n",
      "17 (369, 496, 4) Snare\n",
      "18 (369, 496, 4) Snare\n",
      "19 (369, 496, 4) Snare\n",
      "20 (369, 496, 4) Snare\n",
      "21 (369, 496, 4) Snare\n",
      "22 (369, 496, 4) Snare\n",
      "23 (369, 496, 4) Snare\n",
      "24 (369, 496, 4) Snare\n",
      "25 (369, 496, 4) Snare\n",
      "26 (369, 496, 4) Snare\n",
      "27 (369, 496, 4) Snare\n",
      "28 (369, 496, 4) Snare\n",
      "29 (369, 496, 4) Snare\n",
      "30 (369, 496, 4) Snare\n",
      "31 (369, 496, 4) Snare\n",
      "32 (369, 496, 4) Snare\n",
      "33 (369, 496, 4) Snare\n",
      "34 (369, 496, 4) Snare\n",
      "35 (369, 496, 4) Snare\n",
      "36 (369, 496, 4) Snare\n",
      "37 (369, 496, 4) Snare\n",
      "38 (369, 496, 4) Snare\n",
      "39 (369, 496, 4) Snare\n",
      "40 (369, 496, 4) Snare\n",
      "41 (369, 496, 4) Snare\n",
      "42 (369, 496, 4) Snare\n",
      "43 (369, 496, 4) Snare\n",
      "44 (369, 496, 4) Snare\n",
      "45 (369, 496, 4) Snare\n",
      "46 (369, 496, 4) Snare\n",
      "47 (369, 496, 4) Snare\n",
      "48 (369, 496, 4) Snare\n",
      "49 (369, 496, 4) Snare\n",
      "50 (369, 496, 4) Snare\n",
      "51 (369, 496, 4) Snare\n",
      "52 (369, 496, 4) Snare\n",
      "53 (369, 496, 4) Snare\n",
      "54 (369, 496, 4) Snare\n",
      "55 (369, 496, 4) Snare\n",
      "56 (369, 496, 4) Snare\n",
      "57 (369, 496, 4) Snare\n",
      "58 (369, 496, 4) Snare\n",
      "59 (369, 496, 4) Snare\n",
      "60 (369, 496, 4) Snare\n",
      "61 (369, 496, 4) Snare\n",
      "62 (369, 496, 4) Snare\n",
      "63 (369, 496, 4) Snare\n",
      "64 (369, 496, 4) Snare\n",
      "65 (369, 496, 4) Snare\n",
      "66 (369, 496, 4) Snare\n",
      "67 (369, 496, 4) Snare\n",
      "68 (369, 496, 4) Snare\n",
      "69 (369, 496, 4) Snare\n",
      "70 (369, 496, 4) Snare\n",
      "71 (369, 496, 4) Snare\n",
      "72 (369, 496, 4) Snare\n",
      "73 (369, 496, 4) Snare\n",
      "74 (369, 496, 4) Snare\n",
      "75 (369, 496, 4) Snare\n",
      "76 (369, 496, 4) Snare\n",
      "77 (369, 496, 4) Snare\n",
      "78 (369, 496, 4) Snare\n",
      "79 (369, 496, 4) Snare\n",
      "80 (369, 496, 4) Snare\n",
      "81 (369, 496, 4) Snare\n",
      "82 (369, 496, 4) Snare\n",
      "83 (369, 496, 4) Snare\n",
      "84 (369, 496, 4) Snare\n",
      "85 (369, 496, 4) Snare\n",
      "86 (369, 496, 4) Snare\n",
      "87 (369, 496, 4) Snare\n",
      "88 (369, 496, 4) Trumpet\n",
      "89 (369, 496, 4) Trumpet\n",
      "90 (369, 496, 4) Trumpet\n",
      "91 (369, 496, 4) Trumpet\n",
      "92 (369, 496, 4) Trumpet\n",
      "93 (369, 496, 4) Trumpet\n",
      "94 (369, 496, 4) Trumpet\n",
      "95 (369, 496, 4) Trumpet\n",
      "96 (369, 496, 4) Trumpet\n",
      "97 (369, 496, 4) Trumpet\n",
      "98 (369, 496, 4) Trumpet\n",
      "99 (369, 496, 4) Trumpet\n",
      "100 (369, 496, 4) Trumpet\n",
      "101 (369, 496, 4) Trumpet\n",
      "102 (369, 496, 4) Trumpet\n",
      "103 (369, 496, 4) Trumpet\n",
      "104 (369, 496, 4) Trumpet\n",
      "105 (369, 496, 4) Trumpet\n",
      "106 (369, 496, 4) Trumpet\n",
      "107 (369, 496, 4) Trumpet\n",
      "108 (369, 496, 4) Trumpet\n",
      "109 (369, 496, 4) Trumpet\n",
      "110 (369, 496, 4) Trumpet\n",
      "111 (369, 496, 4) Trumpet\n",
      "112 (369, 496, 4) Trumpet\n",
      "113 (369, 496, 4) Trumpet\n",
      "114 (369, 496, 4) Trumpet\n",
      "115 (369, 496, 4) Trumpet\n",
      "116 (369, 496, 4) Trumpet\n",
      "117 (369, 496, 4) Trumpet\n",
      "118 (369, 496, 4) Trumpet\n",
      "119 (369, 496, 4) Trumpet\n",
      "120 (369, 496, 4) Trumpet\n",
      "121 (369, 496, 4) Trumpet\n",
      "122 (369, 496, 4) Trumpet\n",
      "123 (369, 496, 4) Trumpet\n",
      "124 (369, 496, 4) Trumpet\n",
      "125 (369, 496, 4) Trumpet\n",
      "126 (369, 496, 4) Trumpet\n",
      "127 (369, 496, 4) Trumpet\n",
      "128 (369, 496, 4) Trumpet\n",
      "129 (369, 496, 4) Trumpet\n",
      "130 (369, 496, 4) Trumpet\n",
      "131 (369, 496, 4) Trumpet\n",
      "132 (369, 496, 4) Trumpet\n",
      "133 (369, 496, 4) Trumpet\n",
      "134 (369, 496, 4) Trumpet\n",
      "135 (369, 496, 4) Trumpet\n",
      "136 (369, 496, 4) Trumpet\n",
      "137 (369, 496, 4) Trumpet\n",
      "138 (369, 496, 4) Trumpet\n",
      "139 (369, 496, 4) Trumpet\n",
      "140 (369, 496, 4) Trumpet\n",
      "141 (369, 496, 4) Trumpet\n",
      "142 (369, 496, 4) Trumpet\n",
      "143 (369, 496, 4) Trumpet\n",
      "144 (369, 496, 4) Trumpet\n",
      "145 (369, 496, 4) Trumpet\n",
      "146 (369, 496, 4) Trumpet\n",
      "147 (369, 496, 4) Trumpet\n",
      "148 (369, 496, 4) Trumpet\n",
      "149 (369, 496, 4) Trumpet\n",
      "150 (369, 496, 4) Trumpet\n",
      "151 (369, 496, 4) Trumpet\n",
      "152 (369, 496, 4) Trumpet\n",
      "153 (369, 496, 4) Trumpet\n",
      "154 (369, 496, 4) Trumpet\n",
      "155 (369, 496, 4) Trumpet\n",
      "156 (369, 496, 4) Trumpet\n",
      "157 (369, 496, 4) Trumpet\n",
      "158 (369, 496, 4) Trumpet\n",
      "159 (369, 496, 4) Trumpet\n",
      "160 (369, 496, 4) Trumpet\n",
      "161 (369, 496, 4) Trumpet\n",
      "162 (369, 496, 4) Trumpet\n",
      "163 (369, 496, 4) Trumpet\n",
      "164 (369, 496, 4) Trumpet\n",
      "165 (369, 496, 4) Trumpet\n",
      "166 (369, 496, 4) Trumpet\n",
      "167 (369, 496, 4) Trumpet\n",
      "168 (369, 496, 4) Trumpet\n",
      "169 (369, 496, 4) Trumpet\n",
      "170 (369, 496, 4) Trumpet\n",
      "171 (369, 496, 4) Violin\n",
      "172 (369, 496, 4) Violin\n",
      "173 (369, 496, 4) Violin\n",
      "174 (369, 496, 4) Violin\n",
      "175 (369, 496, 4) Violin\n",
      "176 (369, 496, 4) Violin\n",
      "177 (369, 496, 4) Violin\n",
      "178 (369, 496, 4) Violin\n",
      "179 (369, 496, 4) Violin\n",
      "180 (369, 496, 4) Violin\n",
      "181 (369, 496, 4) Violin\n",
      "182 (369, 496, 4) Violin\n",
      "183 (369, 496, 4) Violin\n",
      "184 (369, 496, 4) Violin\n",
      "185 (369, 496, 4) Violin\n",
      "186 (369, 496, 4) Violin\n",
      "187 (369, 496, 4) Violin\n",
      "188 (369, 496, 4) Violin\n",
      "189 (369, 496, 4) Violin\n",
      "190 (369, 496, 4) Violin\n",
      "191 (369, 496, 4) Violin\n",
      "192 (369, 496, 4) Violin\n",
      "193 (369, 496, 4) Violin\n",
      "194 (369, 496, 4) Violin\n",
      "195 (369, 496, 4) Violin\n",
      "196 (369, 496, 4) Violin\n",
      "197 (369, 496, 4) Violin\n",
      "198 (369, 496, 4) Violin\n",
      "199 (369, 496, 4) Violin\n",
      "200 (369, 496, 4) Violin\n",
      "201 (369, 496, 4) Violin\n",
      "202 (369, 496, 4) Violin\n",
      "203 (369, 496, 4) Violin\n",
      "204 (369, 496, 4) Violin\n",
      "205 (369, 496, 4) Violin\n",
      "206 (369, 496, 4) Violin\n",
      "207 (369, 496, 4) Violin\n",
      "208 (369, 496, 4) Violin\n",
      "209 (369, 496, 4) Violin\n",
      "210 (369, 496, 4) Violin\n",
      "211 (369, 496, 4) Violin\n",
      "212 (369, 496, 4) Violin\n",
      "213 (369, 496, 4) Violin\n",
      "214 (369, 496, 4) Violin\n",
      "215 (369, 496, 4) Violin\n",
      "216 (369, 496, 4) Violin\n",
      "217 (369, 496, 4) Violin\n",
      "218 (369, 496, 4) Violin\n",
      "219 (369, 496, 4) Violin\n",
      "220 (369, 496, 4) Violin\n",
      "221 (369, 496, 4) Violin\n",
      "222 (369, 496, 4) Violin\n",
      "223 (369, 496, 4) Violin\n",
      "224 (369, 496, 4) Violin\n",
      "225 (369, 496, 4) Violin\n",
      "226 (369, 496, 4) Violin\n",
      "227 (369, 496, 4) Violin\n",
      "228 (369, 496, 4) Violin\n",
      "229 (369, 496, 4) Violin\n",
      "230 (369, 496, 4) Violin\n",
      "231 (369, 496, 4) Violin\n",
      "232 (369, 496, 4) Violin\n",
      "233 (369, 496, 4) Violin\n",
      "234 (369, 496, 4) Violin\n",
      "235 (369, 496, 4) Violin\n",
      "236 (369, 496, 4) Violin\n",
      "237 (369, 496, 4) Violin\n",
      "238 (369, 496, 4) Violin\n",
      "239 (369, 496, 4) Violin\n",
      "240 (369, 496, 4) Violin\n",
      "241 (369, 496, 4) Violin\n"
     ]
    }
   ],
   "source": [
    "instruments_dataset = InstrumentsDataset(csv_file = \"groundtruthdata.csv\", root_dir = \".\")\n",
    "\n",
    "# for i, sample in enumerate(instruments_dataset):\n",
    "#     print(i, sample['image'].shape, sample['instrument'])\n",
    "\n",
    "train_size = int(0.8 * len(instruments_dataset))\n",
    "test_size = len(instruments_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(instruments_dataset, [train_size, test_size])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
